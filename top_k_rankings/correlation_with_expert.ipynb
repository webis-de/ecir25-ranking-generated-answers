{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe19d14-8f7e-4f8e-80d8-9f1c00bcff9d",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe23641-9cc3-48e1-94cf-c374bce2cada",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00362399-f33d-4785-902e-5ab4843f4c13",
   "metadata": {},
   "source": [
    "### Load the model dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1551469-9bfa-42f0-b3a7-24f0d2e6aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def load_model_df():\n",
    "    model_rankings = 'monoT5'\n",
    "    \n",
    "    base_path = f'../indexing/results/{model_rankings}/'\n",
    "    # all_model_dirs = glob.glob(f'../indexing/results/{model_rankings}/*')\n",
    "    all_model_csvs = glob.glob(f'{base_path}/*.csv') \n",
    "    plot_path = f'./plots'\n",
    "    if not os.path.exists(plot_path):\n",
    "        os.makedirs(plot_path)\n",
    "    \n",
    "    number_of_answers = 10\n",
    "    \n",
    "    model_dfs = []\n",
    "    for model_csv in all_model_csvs:\n",
    "        df = pd.read_csv(model_csv)\n",
    "        model_name = model_csv.split(\"/\")[-1].split(\".\")[0].replace(\"_rankings\", \"\")\n",
    "        df[\"model\"] = model_name\n",
    "        model_dfs.append(df)\n",
    "    \n",
    "    all_model_df = pd.concat(model_dfs, ignore_index=True)\n",
    "    all_model_df['is_natural_question'] = all_model_df['query'].str.endswith('?')\n",
    "    all_model_df['weighted_position']  = 1 - all_model_df['weighted_position']\n",
    "\n",
    "    # replace na answers with empty string\n",
    "    all_model_df['text'] = all_model_df['text'].fillna('')\n",
    "    return all_model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99272cb-58b8-4128-9f17-c143f15adbb3",
   "metadata": {},
   "source": [
    "### Load the expert annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa455285-1d69-4ccb-a494-040efb559ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_annotations():\n",
    "    with open(\"expert-annotations.json\", \"r\") as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087283dd-fe93-46e0-a517-0147110e8bc5",
   "metadata": {},
   "source": [
    "### Parse the annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2adafdf-c20d-406b-85a6-2aed9a857e3c",
   "metadata": {},
   "source": [
    "#### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727238fe-872a-4a55-9aef-198b71e01400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_answer_components(answer_id):\n",
    "    splits = answer_id.split(\"_\")\n",
    "    model = \"_\".join(splits[:-3])\n",
    "    qid = splits[-3]\n",
    "    answer_number = splits[-1]\n",
    "    return model, int(qid), int(answer_number)\n",
    "\n",
    "def _clean_dict(result_dict):\n",
    "    results = {}\n",
    "    for k, v in result_dict.items():\n",
    "        try: \n",
    "            model, _, _ = _get_answer_components(k)\n",
    "        except:\n",
    "            model = \"document\"\n",
    "        results[model] = v\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2834d5d9-b30d-4050-b505-d1c435b5457c",
   "metadata": {},
   "source": [
    "#### Get the expert ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97a013e-d74a-4e93-85c4-8cd663ed9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expert_ranks(rankings):\n",
    "    rank_dict = _clean_dict({model: i+1 for i, model in enumerate(rankings)})\n",
    "    return pd.DataFrame([{\"model\": k, \"expert_rank\": v} for k,v in rank_dict.items()]).sort_values(\"expert_rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9cd9b3-7f56-4ed2-a34b-788e1af5246d",
   "metadata": {},
   "source": [
    "#### Get the monoT5 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba37c65-eeb7-45ea-99fb-67d3547dd77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monoT5_scores(items):\n",
    "    score_dict = _clean_dict({item[\"docno\"]: item[\"score\"] for item in items})\n",
    "    return pd.DataFrame([{\"model\": k, \"monoT5_score\": v} for k,v in score_dict.items()]).sort_values(\"monoT5_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e950a6b-4756-4f63-a5f9-bb02d84efe18",
   "metadata": {},
   "source": [
    "### Get the information about query and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe6573e-92f2-4993-8a1d-4c45f9906789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(rankings, df):\n",
    "    results = []\n",
    "    for model in rankings:\n",
    "        try:\n",
    "            model, qid, answer_number = _get_answer_components(model)\n",
    "            results.append({\n",
    "                \"model\": model,\n",
    "                \"qid\": qid,\n",
    "                \"answer_number\": answer_number,\n",
    "            })\n",
    "        except:\n",
    "            results.append({\n",
    "                \"model\": \"document\",\n",
    "                \"qid\": None,\n",
    "                \"answer_number\": None,\n",
    "            })\n",
    "    df = pd.DataFrame(results)\n",
    "    df.loc[:, \"qid\"] = df.loc[:, \"qid\"].ffill()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc05d49-31fc-4525-b3ed-5372a6beaab3",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a20b5f-027e-4b6f-9a0c-b5e449066dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotation_dict(q_dict, df):\n",
    "    items = q_dict['data'][\"items\"]\n",
    "    rankings = q_dict[\"annotations\"][0][\"result\"][0][\"value\"][\"ranker\"][\"rank\"]\n",
    "    df1 = get_expert_ranks(rankings)\n",
    "    df2 = get_monoT5_scores(items)\n",
    "    df3 = get_ids(rankings, df)\n",
    "    return df1.merge(df2.merge(df3, on=\"model\"), on=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14fc9406-359d-47da-932a-3fd0a5c28fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotations(annotations, df):\n",
    "    result_df = pd.DataFrame()\n",
    "    for q_dict in annotations:\n",
    "        result_df = pd.concat([result_df, process_annotation_dict(q_dict, df)], ignore_index=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0404ff6-daa8-49f2-8662-73481ec24f23",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d304c236-735d-415a-886e-a885abaa5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_model_df()\n",
    "annotations = get_annotations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dcd845-d95a-4338-bb77-a2dbb6aa7ae0",
   "metadata": {},
   "source": [
    "## Example for one query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ffc602e-54e0-45cc-b048-7c58eb7c85f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chatgpt_22_multimedqa_6',\n",
       " 'meta-llama_Llama-2-13b-chat-hf_22_multimedqa_10',\n",
       " 'gpt2-xl_22_multimedqa_10',\n",
       " '01f617ac-9919-44fe-8fc8-2db9ff72b5e7',\n",
       " 'gpt2_22_multimedqa_9']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dict = annotations[0]\n",
    "items = q_dict['data'][\"items\"]\n",
    "rankings = q_dict[\"annotations\"][0][\"result\"][0][\"value\"][\"ranker\"][\"rank\"]\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3574eed-b614-48c2-a6da-1c133fc38002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_expert_ranks(rankings)\n",
    "df2 = get_monoT5_scores(items)\n",
    "df3 = get_ids(rankings, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad8370c9-0b69-4ccc-8ea4-50d702b3383d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>expert_rank</th>\n",
       "      <th>monoT5_score</th>\n",
       "      <th>qid</th>\n",
       "      <th>answer_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatgpt</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.013656</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meta-llama_Llama-2-13b-chat-hf</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.010791</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.094876</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>document</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.024986</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.417914</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  expert_rank  monoT5_score   qid  \\\n",
       "0                         chatgpt            1     -0.013656  22.0   \n",
       "1  meta-llama_Llama-2-13b-chat-hf            2     -0.010791  22.0   \n",
       "2                         gpt2-xl            3     -0.094876  22.0   \n",
       "3                        document            4     -0.024986  22.0   \n",
       "4                            gpt2            5     -5.417914  22.0   \n",
       "\n",
       "   answer_number  \n",
       "0            6.0  \n",
       "1           10.0  \n",
       "2           10.0  \n",
       "3            NaN  \n",
       "4            9.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.merge(df2.merge(df3, on=\"model\"), on=\"model\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee6434-520b-446c-be1b-4a63ce67c34d",
   "metadata": {},
   "source": [
    "## Full annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efbb4dbb-9915-4abb-bea4-32c579840f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>expert_rank</th>\n",
       "      <th>monoT5_score</th>\n",
       "      <th>qid</th>\n",
       "      <th>answer_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatgpt</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.013656</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meta-llama_Llama-2-13b-chat-hf</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.010791</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.094876</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>document</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.024986</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.417914</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  expert_rank  monoT5_score   qid  \\\n",
       "0                         chatgpt            1     -0.013656  22.0   \n",
       "1  meta-llama_Llama-2-13b-chat-hf            2     -0.010791  22.0   \n",
       "2                         gpt2-xl            3     -0.094876  22.0   \n",
       "3                        document            4     -0.024986  22.0   \n",
       "4                            gpt2            5     -5.417914  22.0   \n",
       "\n",
       "   answer_number  \n",
       "0            6.0  \n",
       "1           10.0  \n",
       "2           10.0  \n",
       "3            NaN  \n",
       "4            9.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = process_annotations(annotations, df)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d71a64-5f55-46ce-99b3-16b1a2987cc7",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08deccda-6795-44ca-84cc-c64565d473de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4820ad2-6f8f-4abe-8273-894b7f7b85ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid = 95\n",
    "measure = \"monoT5_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e29ef75d-afcb-481e-9ef6-d87e1286226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_df(result_df, measure=\"monoT5_score\", include_docs=True, inverse_ranking=True):\n",
    "    taus = []\n",
    "    measure_mult = -1 if inverse_ranking else 1\n",
    "    for qid in result_df[\"qid\"].unique():\n",
    "        tmp = result_df.loc[(result_df[\"qid\"]==qid) & (result_df[measure].notna())]\n",
    "        if not include_docs:\n",
    "            tmp = tmp.loc[tmp[\"model\"] != \"document\"]\n",
    "        \n",
    "        tau, p = st.kendalltau(tmp[\"expert_rank\"], measure_mult*tmp[measure])\n",
    "        taus.append({\"qid\": qid, \"tau\": tau, \"p\": p, \"measure\": measure})\n",
    "    return pd.DataFrame(taus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f22bdbb6-562f-4201-bc86-2215751f25ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>tau</th>\n",
       "      <th>p</th>\n",
       "      <th>measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>monoT5_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>monoT5_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>monoT5_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>monoT5_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>monoT5_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid  tau         p       measure\n",
       "0  22.0  0.6  0.233333  monoT5_score\n",
       "1  35.0  1.0  0.016667  monoT5_score\n",
       "2   1.0  0.8  0.083333  monoT5_score\n",
       "3  68.0  0.8  0.083333  monoT5_score\n",
       "4  54.0  1.0  0.016667  monoT5_score"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_df = get_correlation_df(result_df=result_df)\n",
    "tau_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c417bb-0a58-4617-acf1-ee17b6d6bff4",
   "metadata": {},
   "source": [
    "Tau values without documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc32dcfe-e2ca-48de-84fe-bbc58ac4eb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>tau</th>\n",
       "      <th>p</th>\n",
       "      <th>measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>monoT5_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>monoT5_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>monoT5_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>monoT5_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>monoT5_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid       tau         p       measure\n",
       "0  22.0  0.666667  0.333333  monoT5_score\n",
       "1  35.0  1.000000  0.083333  monoT5_score\n",
       "2   1.0  1.000000  0.083333  monoT5_score\n",
       "3  68.0  1.000000  0.083333  monoT5_score\n",
       "4  54.0  1.000000  0.083333  monoT5_score"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_df_no_doc = get_correlation_df(result_df, include_docs=False)\n",
    "tau_df_no_doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d22d6-1d38-4120-a441-0bdc34838f7b",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86715a8a-afa3-4736-8384-8589a3526125",
   "metadata": {},
   "source": [
    "## Determine confidence intervals for Kendalls Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2667a5ec-65cf-45f6-b270-44ee3e45a80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>95_lo</th>\n",
       "      <th>95_hi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure</th>\n",
       "      <th>measure</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monoT5_score</th>\n",
       "      <th>tau</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.502165</td>\n",
       "      <td>0.777835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean     95_lo     95_hi\n",
       "measure      measure                          \n",
       "monoT5_score tau      0.64  0.502165  0.777835"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _ci(agg_df, alpha, col_prefix=\"tau\"):\n",
    "    df_new = pd.DataFrame()\n",
    "    df_new['mean'] = agg_df[col_prefix]['mean']\n",
    "    df_new[f'{int(alpha*100)}_lo'], df_new[f'{int(alpha*100)}_hi'] = st.t.interval(\n",
    "        alpha, \n",
    "        df=agg_df[col_prefix]['count'] - 1,\n",
    "        loc=agg_df[col_prefix]['mean'],\n",
    "        scale=agg_df[col_prefix]['sem'])\n",
    "    df_new['measure'] = col_prefix\n",
    "    df_new.set_index(['measure'], inplace=True, append=True)\n",
    "    return df_new\n",
    "\n",
    "agg_df = tau_df.groupby(\"measure\").agg([\"mean\", \"count\", \"sem\"])\n",
    "df_ci = _ci(agg_df, .95, 'tau')\n",
    "df_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b412be6-fda6-4796-b0c0-63b3f74366c5",
   "metadata": {},
   "source": [
    "Confidence intervals without documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28627d65-1bd0-4881-ac66-516cf1aaae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>95_lo</th>\n",
       "      <th>95_hi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure</th>\n",
       "      <th>measure</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monoT5_score</th>\n",
       "      <th>tau</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.6318</td>\n",
       "      <td>0.901534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mean   95_lo     95_hi\n",
       "measure      measure                            \n",
       "monoT5_score tau      0.766667  0.6318  0.901534"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df_no_doc = tau_df_no_doc.groupby(\"measure\").agg([\"mean\", \"count\", \"sem\"])\n",
    "df_ci_no_doc = _ci(agg_df_no_doc, .95, 'tau')\n",
    "df_ci_no_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6f5ef-08f3-492e-a5a1-42c90fc17875",
   "metadata": {},
   "source": [
    "### Correlation values per Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62033dac-dba2-465a-97bf-e9da5572cd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>measure</th>\n",
       "      <th>monoT5_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52.0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54.0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.0</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57.0</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68.0</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81.0</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83.0</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85.0</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94.0</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95.0</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96.0</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.0</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101.0</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102.0</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114.0</th>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116.0</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117.0</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "measure  monoT5_score\n",
       "qid                  \n",
       "1.0               0.8\n",
       "22.0              0.6\n",
       "35.0              1.0\n",
       "52.0              1.0\n",
       "54.0              1.0\n",
       "55.0              0.6\n",
       "57.0              0.2\n",
       "68.0              0.8\n",
       "81.0              0.8\n",
       "83.0              0.4\n",
       "85.0              0.8\n",
       "94.0              0.4\n",
       "95.0              0.8\n",
       "96.0              0.4\n",
       "97.0              0.6\n",
       "101.0             0.6\n",
       "102.0             0.8\n",
       "114.0            -0.2\n",
       "116.0             0.6\n",
       "117.0             0.8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_df.pivot_table(values='tau', index='qid', columns='measure', aggfunc='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e662e-ac06-454e-ae7a-504a409febfd",
   "metadata": {},
   "source": [
    "### Position according to expert and monoT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa6b4851-f65a-42de-96db-50c5865e8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = result_df.copy(deep=True)\n",
    "\n",
    "model_map = {\"chatgpt\": \"ChatGPT\",\n",
    "             \"meta-llama_Llama-2-13b-chat-hf\": \"Lla 13B\",\n",
    "             \"gpt2-xl\": \"GPT-2 XL\",\n",
    "             \"gpt2\": \"GPT-2\",\n",
    "             \"document\": \"Doc.\"}\n",
    "pos_df[\"model\"] = pos_df[\"model\"].map(model_map)\n",
    "pos_df[\"monoT5_rank\"] = pos_df.groupby(\"qid\")[\"monoT5_score\"].rank(method=\"dense\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87985e96-431f-4d8b-bd68-b83d08b5c432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>expert_rank</th>\n",
       "      <th>monoT5_score</th>\n",
       "      <th>qid</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>monoT5_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.013656</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lla 13B</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.010791</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-2 XL</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.094876</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doc.</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.024986</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-2</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.417914</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.010407</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Lla 13B</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.009214</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Doc.</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.012032</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GPT-2 XL</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.026931</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GPT-2</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.036496</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  expert_rank  monoT5_score   qid  answer_number  monoT5_rank\n",
       "0    ChatGPT            1     -0.013656  22.0            6.0          2.0\n",
       "1    Lla 13B            2     -0.010791  22.0           10.0          1.0\n",
       "2   GPT-2 XL            3     -0.094876  22.0           10.0          4.0\n",
       "3       Doc.            4     -0.024986  22.0            NaN          3.0\n",
       "4      GPT-2            5     -5.417914  22.0            9.0          5.0\n",
       "..       ...          ...           ...   ...            ...          ...\n",
       "95   ChatGPT            1     -0.010407  85.0            5.0          2.0\n",
       "96   Lla 13B            2     -0.009214  85.0           10.0          1.0\n",
       "97      Doc.            3     -0.012032  85.0            NaN          3.0\n",
       "98  GPT-2 XL            4     -0.026931  85.0            3.0          4.0\n",
       "99     GPT-2            5     -0.036496  85.0            5.0          5.0\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b37631ce-3634-4e40-93f3-7c4ee741fde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ChatGPT</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Lla 13B</th>\n",
       "      <th colspan=\"2\" halign=\"left\">GPT-2 XL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">GPT-2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Doc.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>expert_rank</th>\n",
       "      <th>monoT5_rank</th>\n",
       "      <th>expert_rank</th>\n",
       "      <th>monoT5_rank</th>\n",
       "      <th>expert_rank</th>\n",
       "      <th>monoT5_rank</th>\n",
       "      <th>expert_rank</th>\n",
       "      <th>monoT5_rank</th>\n",
       "      <th>expert_rank</th>\n",
       "      <th>monoT5_rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model     ChatGPT                 Lla 13B                GPT-2 XL              \\\n",
       "      expert_rank monoT5_rank expert_rank monoT5_rank expert_rank monoT5_rank   \n",
       "qid                                                                             \n",
       "1.0             1         1.0           2         2.0           3         3.0   \n",
       "22.0            1         2.0           2         1.0           3         4.0   \n",
       "35.0            1         1.0           2         2.0           3         3.0   \n",
       "52.0            1         1.0           2         2.0           3         3.0   \n",
       "54.0            1         1.0           2         2.0           4         4.0   \n",
       "\n",
       "model       GPT-2                    Doc.              \n",
       "      expert_rank monoT5_rank expert_rank monoT5_rank  \n",
       "qid                                                    \n",
       "1.0             4         5.0           5         4.0  \n",
       "22.0            5         5.0           4         3.0  \n",
       "35.0            5         5.0           4         4.0  \n",
       "52.0            5         5.0           4         4.0  \n",
       "54.0            5         5.0           3         3.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df = pos_df.pivot_table(values=[\"expert_rank\", \"monoT5_rank\"], \n",
    "                              index='qid', \n",
    "                              columns=['model'], \n",
    "                              aggfunc='first', \n",
    "                              dropna=False)\n",
    "pivot_df = pivot_df.reorder_levels(order=[1, 0], axis=1).reindex(columns=model_map.values(), level=\"model\")\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b8f98-c9be-4c3d-bf9e-80b1c228dec1",
   "metadata": {},
   "source": [
    "#### Visualization for each model\n",
    "- Five blocks for each query (possible ranks)\n",
    "- Each block can have one of 4 scenarios\n",
    "    - Rank not set\n",
    "    - expert = monoT5\n",
    "    - only expert\n",
    "    - only monoT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89ce465d-9fce-4550-9aca-65863c97b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _label_model_ranks(model_row):\n",
    "    positions = {idx: \"not set\" for idx in range(1, 6)}\n",
    "    exp_rank, t5_rank = model_row[\"expert_rank\"], model_row[\"monoT5_rank\"]\n",
    "\n",
    "    # Assign initial labels as if there were no concordant ranks\n",
    "    positions[exp_rank] = \"only expert\"\n",
    "    positions[t5_rank] = \"only t5\"\n",
    "    \n",
    "    # Correct for concordant ranks\n",
    "    if exp_rank == t5_rank:\n",
    "        positions[exp_rank] = \"expert == t5\"\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf13ab2e-5dbe-4da1-a492-d3494633be0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expert_rank    2.0\n",
       "monoT5_rank    1.0\n",
       "Name: 22.0, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_row=pivot_df.iloc[1][\"Lla 13B\"]\n",
    "model_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6910d38e-16d9-461d-a6e7-d6bf03d6c439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'only t5', 2: 'only expert', 3: 'not set', 4: 'not set', 5: 'not set'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = _label_model_ranks(model_row)\n",
    "model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc74a4-e9af-4c92-aed6-2f2d6c08e5fc",
   "metadata": {},
   "source": [
    "Apply labeling to each query and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a5c051b-614d-4092-bf23-fad7fb4cf578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_query(row):\n",
    "    return pd.Series({model: _label_model_ranks(row[model])for model in model_map.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34c96c08-2ed6-4277-afdd-41daaa9a10c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChatGPT</th>\n",
       "      <th>Lla 13B</th>\n",
       "      <th>GPT-2 XL</th>\n",
       "      <th>GPT-2</th>\n",
       "      <th>Doc.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>{1: 'expert == t5', 2: 'not set', 3: 'not set'...</td>\n",
       "      <td>{1: 'not set', 2: 'expert == t5', 3: 'not set'...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'expert == t5'...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'not set', 4: ...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'not set', 4: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>{1: 'only expert', 2: 'only t5', 3: 'not set',...</td>\n",
       "      <td>{1: 'only t5', 2: 'only expert', 3: 'not set',...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'only expert',...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'not set', 4: ...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'only t5', 4: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>{1: 'expert == t5', 2: 'not set', 3: 'not set'...</td>\n",
       "      <td>{1: 'not set', 2: 'expert == t5', 3: 'not set'...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'expert == t5'...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'not set', 4: ...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'not set', 4: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52.0</th>\n",
       "      <td>{1: 'expert == t5', 2: 'not set', 3: 'not set'...</td>\n",
       "      <td>{1: 'not set', 2: 'expert == t5', 3: 'not set'...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'expert == t5'...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'not set', 4: ...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'not set', 4: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54.0</th>\n",
       "      <td>{1: 'expert == t5', 2: 'not set', 3: 'not set'...</td>\n",
       "      <td>{1: 'not set', 2: 'expert == t5', 3: 'not set'...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'not set', 4: ...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'not set', 4: ...</td>\n",
       "      <td>{1: 'not set', 2: 'not set', 3: 'expert == t5'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ChatGPT  \\\n",
       "qid                                                       \n",
       "1.0   {1: 'expert == t5', 2: 'not set', 3: 'not set'...   \n",
       "22.0  {1: 'only expert', 2: 'only t5', 3: 'not set',...   \n",
       "35.0  {1: 'expert == t5', 2: 'not set', 3: 'not set'...   \n",
       "52.0  {1: 'expert == t5', 2: 'not set', 3: 'not set'...   \n",
       "54.0  {1: 'expert == t5', 2: 'not set', 3: 'not set'...   \n",
       "\n",
       "                                                Lla 13B  \\\n",
       "qid                                                       \n",
       "1.0   {1: 'not set', 2: 'expert == t5', 3: 'not set'...   \n",
       "22.0  {1: 'only t5', 2: 'only expert', 3: 'not set',...   \n",
       "35.0  {1: 'not set', 2: 'expert == t5', 3: 'not set'...   \n",
       "52.0  {1: 'not set', 2: 'expert == t5', 3: 'not set'...   \n",
       "54.0  {1: 'not set', 2: 'expert == t5', 3: 'not set'...   \n",
       "\n",
       "                                               GPT-2 XL  \\\n",
       "qid                                                       \n",
       "1.0   {1: 'not set', 2: 'not set', 3: 'expert == t5'...   \n",
       "22.0  {1: 'not set', 2: 'not set', 3: 'only expert',...   \n",
       "35.0  {1: 'not set', 2: 'not set', 3: 'expert == t5'...   \n",
       "52.0  {1: 'not set', 2: 'not set', 3: 'expert == t5'...   \n",
       "54.0  {1: 'not set', 2: 'not set', 3: 'not set', 4: ...   \n",
       "\n",
       "                                                  GPT-2  \\\n",
       "qid                                                       \n",
       "1.0   {1: 'not set', 2: 'not set', 3: 'not set', 4: ...   \n",
       "22.0  {1: 'not set', 2: 'not set', 3: 'not set', 4: ...   \n",
       "35.0  {1: 'not set', 2: 'not set', 3: 'not set', 4: ...   \n",
       "52.0  {1: 'not set', 2: 'not set', 3: 'not set', 4: ...   \n",
       "54.0  {1: 'not set', 2: 'not set', 3: 'not set', 4: ...   \n",
       "\n",
       "                                                   Doc.  \n",
       "qid                                                      \n",
       "1.0   {1: 'not set', 2: 'not set', 3: 'not set', 4: ...  \n",
       "22.0  {1: 'not set', 2: 'not set', 3: 'only t5', 4: ...  \n",
       "35.0  {1: 'not set', 2: 'not set', 3: 'not set', 4: ...  \n",
       "52.0  {1: 'not set', 2: 'not set', 3: 'not set', 4: ...  \n",
       "54.0  {1: 'not set', 2: 'not set', 3: 'expert == t5'...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_df = pivot_df.apply(lambda row: label_query(row), axis=1)\n",
    "vis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e1f21-a241-40ad-b270-18cfabd1277e",
   "metadata": {},
   "source": [
    "### Create the visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9a72bcb-2c9a-49d5-89c8-61bfc1134b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.offsetbox import AnnotationBbox, AuxTransformBox\n",
    "\n",
    "box_size = 1\n",
    "spacing = 0.15\n",
    "\n",
    "def _rank_design(rank, letter, ax):\n",
    "    # Define designs\n",
    "    t5_color, t5_hatch, t5_edgecolor = '#ffd87d', '/', '#c78824'\n",
    "    exp_color, exp_hatch, exp_edgecolor = '#d3f8f7', '\\\\', '#3a91a5'\n",
    "    t5_exp_color, t5_exp_hatch, t5_exp_edgecolor = '#9ed977',  'x', '#349850'\n",
    "\n",
    "    # Determine box position\n",
    "    x = (rank - 1) * (box_size + spacing)\n",
    "    y = 0\n",
    "    \n",
    "    # Set the annotation boxes\n",
    "    r = patches.Rectangle((x, y), box_size, box_size, facecolor='none', edgecolor='none', linewidth=0)\n",
    "    offsetbox = AuxTransformBox(ax.transData)\n",
    "    offsetbox.add_artist(r)\n",
    "    lw = 6.5\n",
    "    frame = AnnotationBbox(offsetbox, (x + box_size/2., y + box_size/2.), boxcoords=\"data\", pad=0, fontsize=lw/2,\n",
    "                           bboxprops=dict(facecolor=\"none\", edgecolor='grey', linewidth=lw/2))\n",
    "\n",
    "    # Create the square based on t5 and expert rank\n",
    "    match letter:\n",
    "        case \"expert == t5\":\n",
    "            square = patches.Rectangle((x, y), box_size, box_size, hatch_linewidth=lw,\n",
    "                                       facecolor=t5_exp_color, edgecolor=t5_exp_edgecolor, hatch=t5_exp_hatch)\n",
    "        case \"only expert\":\n",
    "            square = patches.Rectangle((x, y), box_size, box_size, hatch_linewidth=lw,\n",
    "                                       facecolor=exp_color, edgecolor=exp_edgecolor, hatch=exp_hatch)\n",
    "        case \"only t5\":\n",
    "            square = patches.Rectangle((x, y), box_size, box_size, hatch_linewidth=lw,\n",
    "                                       facecolor=t5_color, edgecolor=t5_edgecolor, hatch=t5_hatch)\n",
    "        case _:\n",
    "            square = patches.Rectangle((x, y), box_size, box_size, facecolor='white', edgecolor='none')\n",
    "    \n",
    "    ax.add_patch(square)\n",
    "    ax.add_artist(frame)\n",
    "\n",
    "def _create_rank_visualization(model_dict, model, qid):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Iterate over the dictionary to create boxes\n",
    "    for rank, letter in model_dict.items():\n",
    "        _rank_design(rank, letter, ax)\n",
    "    \n",
    "    ax.set_xlim(0, 5 * box_size + 4 * spacing)\n",
    "    ax.set_ylim(0, box_size)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.axis('off') \n",
    "\n",
    "    filename = _create_filename(model, qid)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('rank_visualization', f'{filename}.pdf'), dpi=500, transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _create_filename(model, qid):\n",
    "    model_name = model.lower().replace(\" \", \"_\").replace(\".\", \"\")\n",
    "    return f'{model_name}_{int(qid)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a2dc5ea-dc54-4b34-b361-311103c2d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"rank_visualization\", exist_ok=True)\n",
    "for qid, row in vis_df.iterrows():\n",
    "    for model in row.index:\n",
    "        _create_rank_visualization(model_dict=row[model], model=model, qid=int(qid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224963d5-bc04-4788-8913-28c214733a1c",
   "metadata": {},
   "source": [
    "# Latex Table:\n",
    "Create joint table of Kendalls Tau and Rank visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aec3463c-9a45-4730-a6c4-7ee068f15e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latex_df(vis_df, tau_df):\n",
    "    df1 = pd.DataFrame([_row_to_latex_cmd(row, qid) for qid, row in vis_df.iterrows()])\n",
    "    df2 = tau_df.pivot_table(values='tau', index='qid', columns='measure', aggfunc='first').reset_index()\n",
    "    df2[\"qid\"] = df2[\"qid\"].astype(int) \n",
    "    df = df2.merge(df1, on=\"qid\")[['qid', 'ChatGPT', 'Lla 13B', 'GPT-2 XL', 'GPT-2','Doc.', 'monoT5_score']]\n",
    "    return df.rename(columns={\"monoT5_score\": r\"Kendall's $\\tau$\"})\n",
    "        \n",
    "def _row_to_latex_cmd(row, qid):\n",
    "    dict_ = {model: _model_to_latex_cmd(model, qid) for model in row.index}\n",
    "    dict_[\"qid\"] = int(qid)\n",
    "    return dict_\n",
    "\n",
    "def _model_to_latex_cmd(model, qid):\n",
    "    filename = _create_filename(model, qid)\n",
    "    return \"\\\\provideranks{\" + filename + \"}\"    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "beaeef3c-380a-4632-8a1a-4cea808e10e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>ChatGPT</th>\n",
       "      <th>Lla 13B</th>\n",
       "      <th>GPT-2 XL</th>\n",
       "      <th>GPT-2</th>\n",
       "      <th>Doc.</th>\n",
       "      <th>Kendall's $\\tau$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\provideranks{chatgpt_1}</td>\n",
       "      <td>\\provideranks{lla_13b_1}</td>\n",
       "      <td>\\provideranks{gpt-2_xl_1}</td>\n",
       "      <td>\\provideranks{gpt-2_1}</td>\n",
       "      <td>\\provideranks{doc_1}</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>\\provideranks{chatgpt_22}</td>\n",
       "      <td>\\provideranks{lla_13b_22}</td>\n",
       "      <td>\\provideranks{gpt-2_xl_22}</td>\n",
       "      <td>\\provideranks{gpt-2_22}</td>\n",
       "      <td>\\provideranks{doc_22}</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>\\provideranks{chatgpt_35}</td>\n",
       "      <td>\\provideranks{lla_13b_35}</td>\n",
       "      <td>\\provideranks{gpt-2_xl_35}</td>\n",
       "      <td>\\provideranks{gpt-2_35}</td>\n",
       "      <td>\\provideranks{doc_35}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>\\provideranks{chatgpt_52}</td>\n",
       "      <td>\\provideranks{lla_13b_52}</td>\n",
       "      <td>\\provideranks{gpt-2_xl_52}</td>\n",
       "      <td>\\provideranks{gpt-2_52}</td>\n",
       "      <td>\\provideranks{doc_52}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>\\provideranks{chatgpt_54}</td>\n",
       "      <td>\\provideranks{lla_13b_54}</td>\n",
       "      <td>\\provideranks{gpt-2_xl_54}</td>\n",
       "      <td>\\provideranks{gpt-2_54}</td>\n",
       "      <td>\\provideranks{doc_54}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                    ChatGPT                    Lla 13B  \\\n",
       "0    1   \\provideranks{chatgpt_1}   \\provideranks{lla_13b_1}   \n",
       "1   22  \\provideranks{chatgpt_22}  \\provideranks{lla_13b_22}   \n",
       "2   35  \\provideranks{chatgpt_35}  \\provideranks{lla_13b_35}   \n",
       "3   52  \\provideranks{chatgpt_52}  \\provideranks{lla_13b_52}   \n",
       "4   54  \\provideranks{chatgpt_54}  \\provideranks{lla_13b_54}   \n",
       "\n",
       "                     GPT-2 XL                    GPT-2                   Doc.  \\\n",
       "0   \\provideranks{gpt-2_xl_1}   \\provideranks{gpt-2_1}   \\provideranks{doc_1}   \n",
       "1  \\provideranks{gpt-2_xl_22}  \\provideranks{gpt-2_22}  \\provideranks{doc_22}   \n",
       "2  \\provideranks{gpt-2_xl_35}  \\provideranks{gpt-2_35}  \\provideranks{doc_35}   \n",
       "3  \\provideranks{gpt-2_xl_52}  \\provideranks{gpt-2_52}  \\provideranks{doc_52}   \n",
       "4  \\provideranks{gpt-2_xl_54}  \\provideranks{gpt-2_54}  \\provideranks{doc_54}   \n",
       "\n",
       "   Kendall's $\\tau$  \n",
       "0               0.8  \n",
       "1               0.6  \n",
       "2               1.0  \n",
       "3               1.0  \n",
       "4               1.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_df = create_latex_df(vis_df, tau_df)\n",
    "latex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "732a937f-583b-4ac9-a222-2cb711b91393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rlllllr}\n",
      "\\toprule\n",
      "qid & ChatGPT & Lla 13B & GPT-2 XL & GPT-2 & Doc. & Kendall's $\\tau$ \\\\\n",
      "\\midrule\n",
      "1 & \\provideranks{chatgpt_1} & \\provideranks{lla_13b_1} & \\provideranks{gpt-2_xl_1} & \\provideranks{gpt-2_1} & \\provideranks{doc_1} & 0.800000 \\\\\n",
      "22 & \\provideranks{chatgpt_22} & \\provideranks{lla_13b_22} & \\provideranks{gpt-2_xl_22} & \\provideranks{gpt-2_22} & \\provideranks{doc_22} & 0.600000 \\\\\n",
      "35 & \\provideranks{chatgpt_35} & \\provideranks{lla_13b_35} & \\provideranks{gpt-2_xl_35} & \\provideranks{gpt-2_35} & \\provideranks{doc_35} & 1.000000 \\\\\n",
      "52 & \\provideranks{chatgpt_52} & \\provideranks{lla_13b_52} & \\provideranks{gpt-2_xl_52} & \\provideranks{gpt-2_52} & \\provideranks{doc_52} & 1.000000 \\\\\n",
      "54 & \\provideranks{chatgpt_54} & \\provideranks{lla_13b_54} & \\provideranks{gpt-2_xl_54} & \\provideranks{gpt-2_54} & \\provideranks{doc_54} & 1.000000 \\\\\n",
      "55 & \\provideranks{chatgpt_55} & \\provideranks{lla_13b_55} & \\provideranks{gpt-2_xl_55} & \\provideranks{gpt-2_55} & \\provideranks{doc_55} & 0.600000 \\\\\n",
      "57 & \\provideranks{chatgpt_57} & \\provideranks{lla_13b_57} & \\provideranks{gpt-2_xl_57} & \\provideranks{gpt-2_57} & \\provideranks{doc_57} & 0.200000 \\\\\n",
      "68 & \\provideranks{chatgpt_68} & \\provideranks{lla_13b_68} & \\provideranks{gpt-2_xl_68} & \\provideranks{gpt-2_68} & \\provideranks{doc_68} & 0.800000 \\\\\n",
      "81 & \\provideranks{chatgpt_81} & \\provideranks{lla_13b_81} & \\provideranks{gpt-2_xl_81} & \\provideranks{gpt-2_81} & \\provideranks{doc_81} & 0.800000 \\\\\n",
      "83 & \\provideranks{chatgpt_83} & \\provideranks{lla_13b_83} & \\provideranks{gpt-2_xl_83} & \\provideranks{gpt-2_83} & \\provideranks{doc_83} & 0.400000 \\\\\n",
      "85 & \\provideranks{chatgpt_85} & \\provideranks{lla_13b_85} & \\provideranks{gpt-2_xl_85} & \\provideranks{gpt-2_85} & \\provideranks{doc_85} & 0.800000 \\\\\n",
      "94 & \\provideranks{chatgpt_94} & \\provideranks{lla_13b_94} & \\provideranks{gpt-2_xl_94} & \\provideranks{gpt-2_94} & \\provideranks{doc_94} & 0.400000 \\\\\n",
      "95 & \\provideranks{chatgpt_95} & \\provideranks{lla_13b_95} & \\provideranks{gpt-2_xl_95} & \\provideranks{gpt-2_95} & \\provideranks{doc_95} & 0.800000 \\\\\n",
      "96 & \\provideranks{chatgpt_96} & \\provideranks{lla_13b_96} & \\provideranks{gpt-2_xl_96} & \\provideranks{gpt-2_96} & \\provideranks{doc_96} & 0.400000 \\\\\n",
      "97 & \\provideranks{chatgpt_97} & \\provideranks{lla_13b_97} & \\provideranks{gpt-2_xl_97} & \\provideranks{gpt-2_97} & \\provideranks{doc_97} & 0.600000 \\\\\n",
      "101 & \\provideranks{chatgpt_101} & \\provideranks{lla_13b_101} & \\provideranks{gpt-2_xl_101} & \\provideranks{gpt-2_101} & \\provideranks{doc_101} & 0.600000 \\\\\n",
      "102 & \\provideranks{chatgpt_102} & \\provideranks{lla_13b_102} & \\provideranks{gpt-2_xl_102} & \\provideranks{gpt-2_102} & \\provideranks{doc_102} & 0.800000 \\\\\n",
      "114 & \\provideranks{chatgpt_114} & \\provideranks{lla_13b_114} & \\provideranks{gpt-2_xl_114} & \\provideranks{gpt-2_114} & \\provideranks{doc_114} & -0.200000 \\\\\n",
      "116 & \\provideranks{chatgpt_116} & \\provideranks{lla_13b_116} & \\provideranks{gpt-2_xl_116} & \\provideranks{gpt-2_116} & \\provideranks{doc_116} & 0.600000 \\\\\n",
      "117 & \\provideranks{chatgpt_117} & \\provideranks{lla_13b_117} & \\provideranks{gpt-2_xl_117} & \\provideranks{gpt-2_117} & \\provideranks{doc_117} & 0.800000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_df.round(4).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d99c8-c9a3-440a-acbc-1a7c5b27f193",
   "metadata": {},
   "source": [
    "## Create examples for latex caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fbdfaa9-ab0c-422c-a04c-17079bb97e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in [\"only t5\", \"only expert\", \"expert == t5\"]:\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    _rank_design(rank=1, letter=letter, ax=ax)\n",
    "    ax.set_xlim(0, 5 * box_size + 4 * spacing)\n",
    "    ax.set_ylim(0, box_size)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.axis('off') \n",
    "\n",
    "    suffix = letter.replace(\" == \", \"-eq-\").replace(\"only \", \"\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('rank_visualization', f'example-{suffix}.pdf'), dpi=500, transparent=True)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b787459-7315-41ad-b062-c51b5b92d978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chs-answers",
   "language": "python",
   "name": "chs-answers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
